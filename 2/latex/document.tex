\documentclass[11pt]{scrartcl}
\usepackage[top=1cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{graphicx,float}
\usepackage{url}
\usepackage[T1]{fontenc}
\usepackage[font=small,labelfont=bf,tableposition=top]{caption}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algorithm, algorithmic}
%opening
\title{Project Report 2}
\author{Fuyuan Lyu, Tianyu Shi, Dingyi Zhuang}

\begin{document}

\maketitle

\begin{abstract}
In this project, we try to implement different models based on scikit-learn and other libraries and evaluate these models on two dataset: 20 news group dataset, which is a multi-class classification task, and IMDB Reviews dataset, which is a binary classification task. When extracting feature vectors, we tried TF-IDF or used Glove embedding. We also tried to remove stop words, do Principal Component Analysis(PCA), Linear Discriminant Analysis(LDA) or TSNE upon TF-IDF feature extractor. In the models implementation stage, we use models include but not limited to: SVM, Logistic Regression, Decision trees, Ada Boost, random forest, XGBoost, Multiple layer perceptron(MLP), LSTM. We also tune the hyper-parameter with greedy search method. XXX model with XXX techniques excels other upon IMDB Review dataset with XXX \% accuracy.
\end{abstract}

\section{Introduction}
The goal of this project is to investigate the performance of different models upon two different datasets: 20 newsf group dataset and IMDB Reviews dataset and perform hyper-parameter tuning.

The 20 news group dataset is a 20-class classification task with approximately 20000 newsgroup documents evenly spread\cite{Lang95}. While the IMDB Reviews dataset is a binary sentimental classification task with 25000 movie reviews for both training and testing\cite{maas-EtAl:2011:ACL-HLT2011}.

In the pre-processing stage, we mainly try two types of techniques. First is TF-IDF based counting features with different pre-processing tricks, such as removing stop word, Principal Component Analysis(PCA), Linear Discriminant Analysis(LDA) or TSNE. Second is using pre-trained global vector representation to embed the word vector. Here we use GloVe, an unsupervised learning algorithm to obtain vector representation\cite{pennington2014glove}.

As for the model part, we try several different methods, include but not limited to: SVM, Logistic Regression, Decision trees, Ada Boost, random forest, XGBoost, Multiple-layer perceptron(MLP) and LSTM-based neural network.

In the hyper-parameter tuning process, we separate the model into two categorizes. SVM, Logistic Regression, Decision trees, Ada Boost and random forest are tuned to improve performance. XGBoost, Multiple-layer perceptron(MLP) and LSTM-based neural network are not tuned due to the lack of computation power.

Based on the result we obtained, XXXXX.


\section{Related Work}
Text classification intends to assign predefined labels to text documents \cite{allahyari2017brief,thangaraj2018text}. Firstly, probabilistic classifiers have gained a lot of popularity and shown markable performance \cite{chakrabarti1997using,joachims1996probabilistic,koller1997hierarchically,larkey1996combining}. These probabilistic methods introduce prior assumptions about how the data (words in documents) are generated and to use a probabilistic model on these assumptions. Besides probabilistic models, the hierarchical structures of decision trees is appealing. In the context of text data, the conditions on the trese nodes are usually defined as the terms in the documents, e.g. the presence or absence of a particular term in the document \cite{breiman1984classification,duda2012pattern}. Decision trees are also combined with boosting techniques to improve the accuracy of classification \cite{freund1995desicion,schapire2000boostexter}. Owing to the robustness of data, Supported Vector Machines (SVM) are also widely implemented to form linear classifiers for supervised learning classification algorithms \cite{joachims1998text,joachims2001statistical}.

Multiple classes in text classification makes it difficult to pick a particular set of attributes. There are many evolving techniques that adapt the algorithms for multi-class task, including K-nearest neighbor, decision trees and SVM \cite{tang2016multi,yi2011multi}. Recently neural network is widely applied in hierarchical multi-label classification issues. Neural network forms the base of the ensemble with the help of composite stumps \cite{nie2015neural,cerri2014hierarchical}.


\section{Dataset and setup}
We use two dataset to test our model performance. The 20 news group dataset is a 20-class classification task with approximately 20000 newsgroup documents evenly spread\cite{Lang95}. While the IMDB Reviews dataset is a binary sentimental classification task with 25000 movie reviews for both training and testing\cite{maas-EtAl:2011:ACL-HLT2011}. In the feature-extraction stage, we propose two types of methods: TF-IDF based and word2vec based. In the TF-IDF based method, we first tokenize every samples and apply TF-IDF to each. Several other feature engineering techniques, such as removing stop word, Principal Component Analysis(PCA), Linear Discriminant Analysis(LDA) or TSNE. In the word2vec based method, we use pretrained GloVe\cite{pennington2014glove} word representation to represent each sample.

\section{Proposed approach}
For our prediction model, we choose logistic regression, decision tree, support vector machine, adaboot, and random forest as candidate models. Of all the well-known learning methods, decision trees come closest to meeting the requirements for serving as an off-the-shelf procedure for data mining. They are relatively fast to construct and they produce interpretable models (if the trees are small). For naive bayes model,it doesnâ€™t require as much training data, and it can handles both continuous and discrete data. Also, it is not sensitive to irrelevant features. For SVM model, It scales relatively well to high dimensional data. SVM models have generalization in practice, the risk of over-fitting is less in SVM. We choose another multi-layer perceptron  model because it is a very good algorithm to be used to map an N-dimensional input signal to an M-dimensional output signal, this mapping can also be non-linear.  However, this will increase the total training time. Another limitation of the MLP algorithm is that the number of Hidden Neurons must be set by the user, setting this value too low may result in the MLP model underfitting while setting this value too high may result in the MLP model overfitting. 




\section{Results}

The experiments are performed to find a suitable preprocessing and classification technique for the proposal text documentation classifiers. Effect of different preprocessing methods (TF-IDF, stop words removal, SVD and autoencoder) on the performance of the classifiers along with grid-search on tuning the best parameters on each classifiers are also discussed.
\subsubsection*{Analysis of the performance of different classifiers}
Test accuracy of different classifiers on two datasets are shown in Table \ref{accuracy_20} and Table \ref{accuracy_imdb}.

\begin{table}[H]
    \centering
    \begin{tabular}{c|cccccccc}
        \hline
         & NB   & LR & DT & SVC & ADB & RDF & MLP & XGB \\
        \hline
        TF-IDF & & & & & & & & \\
		Stop word removal & & & & & & & & \\
		SVD-2 & & & & & & & & \\
		SVD-3 & & & & & & & & \\
		SVD-4 & & & & & & & & \\
		SVD-5 & & & & & & & & \\
		SVD-6 & & & & & & & & \\
		autoencoder & & & & & & & & \\
		best model params & & & & & & & & \\
        \hline
    \end{tabular} 
    \caption{Accuracy of differnt classifiers on Twenty Century News dataset}
    \label{accuracy_20}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{c|cccccccc}
        \hline
         & NB   & LR & DT & SVC & ADB & RDF & MLP & XGB \\
        \hline
        TF-IDF & & & & & & & & \\
		Stop word removal & & & & & & & & \\
		SVD-2 & & & & & & & & \\
		SVD-3 & & & & & & & & \\
		SVD-4 & & & & & & & & \\
		SVD-5 & & & & & & & & \\
		SVD-6 & & & & & & & & \\
		autoencoder & & & & & & & & \\
		best model params & & & & & & & & \\
        \hline
    \end{tabular} 
    \caption{Accuracy of different classifiers on IMDB dataset}
    \label{accuracy_imdb}
\end{table}

\section{Discussion and Conclusion}

\section{Statement for Contributions}
\begin{itemize}
	\item Fuyuan Lyu: Dataset preprocessing and feature engineering
	\item Tianyu Shi:
	\item Dingyi Zhuang:
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{ref}
\end{document}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T18:11:58.636363Z",
     "start_time": "2020-02-29T18:11:56.521268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tianyushi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import  AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from dataset.dataset import get_twenty_dataset, get_IMDB_dataset\n",
    "from main_dataset import main\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T18:12:10.901074Z",
     "start_time": "2020-02-29T18:11:58.638297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "autoencoder:  11314 114607 256\n",
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# We compare the condition where datasets are\n",
    "# 1. tf-idf\n",
    "# 2. tf-idf + remove_stopping_word\n",
    "# 3. tf-idf + remove_stopping_word + SVD (k=2,3,4,5,6)\n",
    "# 4. tf-idf + remove_stopping_word + autoencoder\n",
    "twenty_dataset_dict = {}\n",
    "IMDB_dataset_dict = {}\n",
    "\n",
    "# 1.\n",
    "twenty_dataset_dict[0]= list(get_twenty_dataset())\n",
    "IMDB_dataset_dict [0] = list(get_IMDB_dataset())\n",
    "\n",
    "# 2.\n",
    "twenty_dataset_dict[1]= list(get_twenty_dataset(remove_stop_word=True))\n",
    "IMDB_dataset_dict [1] = list(get_IMDB_dataset(remove_stop_word=True))\n",
    "\n",
    "# 3. \n",
    "for i in range(2,7):\n",
    "    print(i)\n",
    "    twenty_dataset_dict[i]= list(get_twenty_dataset(remove_stop_word=True,preprocessing_trick='SVD',n_components=i))\n",
    "    IMDB_dataset_dict [i] = list(get_IMDB_dataset(remove_stop_word=True,preprocessing_trick='SVD',n_components=i)) \n",
    "# x_train_20, y_train_20, x_test_20, y_test_20 = get_twenty_dataset()\n",
    "# x_train_imdb, y_train_imdb, x_test_imdb, y_test_imdb = get_IMDB_dataset()\n",
    "\n",
    "# 4.\n",
    "twenty_dataset_dict[7]= list(get_twenty_dataset(remove_stop_word=True,preprocessing_trick='autoencoder',n_components=256))\n",
    "IMDB_dataset_dict [7] = list(get_IMDB_dataset(remove_stop_word=True,preprocessing_trick='autoencoder',n_components=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder:  11314 114607 256\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2944: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tianyushi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "ae_twenty_dataset= list(get_twenty_dataset(remove_stop_word=True,preprocessing_trick='autoencoder',n_components=256))\n",
    "ae_IMDB_dataset = list(get_IMDB_dataset(remove_stop_word=True,preprocessing_trick='autoencoder',n_components=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(ae_twenty_dataset[0], ae_twenty_dataset[1], ae_twenty_dataset[2], ae_twenty_dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(ae_IMDB_dataset[0], ae_IMDB_dataset[1], ae_IMDB_dataset[2], ae_IMDB_dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ['tf-idf','tf-idf, remove stopping word','SVD-2','SVD-3','SVD-4','SVD-5','SVD-6','autoencoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 news results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T18:13:05.749245Z",
     "start_time": "2020-02-29T18:12:10.903032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomialNB model\n",
      "0.7320764737121614\n",
      "logistic regression model\n",
      "Decision Tree model\n",
      "0.46999468932554433\n",
      "SVM model\n",
      "0.8036378120021243\n",
      "AdaBoost model\n",
      "0.5\n",
      "Random forest model\n",
      "0.688396176314392\n",
      "MLPClassifier model\n",
      "0.7705788635156665\n"
     ]
    }
   ],
   "source": [
    "model_dict_20=main(x_train_20, y_train_20, x_test_20, y_test_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T18:14:50.605241Z",
     "start_time": "2020-02-29T18:13:05.751203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomialNB model\n",
      "0.82956\n",
      "logistic regression model\n",
      "Decision Tree model\n",
      "0.70416\n",
      "SVM model\n",
      "0.8772\n",
      "AdaBoost model\n",
      "0.83\n",
      "Random forest model\n",
      "0.8366\n",
      "MLPClassifier model\n",
      "0.87668\n"
     ]
    }
   ],
   "source": [
    "model_dict_imdb=main(x_train_imdb, y_train_imdb, x_test_imdb, y_test_imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "clf_NB = MultinomialNB()\n",
    "clf_LR = LogisticRegression()\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_SVC = LinearSVC()\n",
    "clf_ADB = AdaBoostClassifier()\n",
    "clf_RDF = RandomForestClassifier()\n",
    "clf_NN = MLPClassifier() # Computationally heavy to tune NN\n",
    "clf_XG = XGBClassifier()\n",
    "\n",
    "models_dict = {'NB':clf_NB,'LR': clf_LR,'DT':clf_DT,'SVC':clf_SVC,'ADB':clf_ADB,'RDF':clf_RDF,'NN':clf_NN,'XG':clf_XG}\n",
    "#models_dict = {'XG':clf_XG}\n",
    "models_list = list(models_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tunable parameters ranges for different classifiers\n",
    "para_NB = {'NB__alpha':np.arange(0,2,0.2),'NB__fit_prior':[True,False]}\n",
    "para_LR = {'LR__penalty':['l1','l2','elasticnet'],\n",
    "           'LR__warm_start':[True,False]}\n",
    "para_DT = {'DT__criterion':['gini','entropy'],\n",
    "           'DT__max_features': ['sqrt','log2',None]}\n",
    "para_SVC = {'SVC__penalty': ['l1','l2'],\n",
    "            'SVC__loss': ['hinge','squared_hinge']}\n",
    "para_ADB = {'ADB__n_estimators': [30,50,80,100,120],\n",
    "            'ADB__learning_rate':np.arange(0,1.2,0.2)}\n",
    "para_RDF = {'RDF__criterion':['gini','entropy'],\n",
    "            'RDF__max_features': ['sqrt','log2',None]}\n",
    "para_NN = {'NN__solver':['lbfgs'], 'NN__hidden_layer_sizes' :[(30,1024)],'NN__max_iter':[5000] }\n",
    "para_XG = {'XG__learning_rate':[0.1]}\n",
    "#para_NN = {'NN__hidden_layer_sizes':[(5,),(12,),(25,),(50,),(100,)],\n",
    "#           'NN__activation':['identity','logistic','tanh','relu'],\n",
    "#           'NN__solver':['lbfgs','sgd','adam'],\n",
    "#           'NN__learning_rate':['constant','invscaling','adaptive']}\n",
    "params_list = [para_NB,para_LR,para_DT,para_SVC,para_ADB,para_RDF,para_NN,para_XG]\n",
    "#params_list = [para_XG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print( len(models_list) == len(params_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model specifics which are the same for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b766d0068d93413c88e6bf98b1e829ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Model  NB  for 20 news  tf-idf score = 0.7463\n",
      "Model  NB  for 20 news   tf-idf best params {'NB__alpha': 0.0, 'NB__fit_prior': True}\n",
      "Model  NB  for IMDB  tf-idf  score = 0.8317\n",
      "Model  NB  for IMDB  tf-idf  best params {'NB__alpha': 1.8, 'NB__fit_prior': True}\n",
      "----------\n",
      "Model  NB  for 20 news  tf-idf, remove stopping word score = 0.7979\n",
      "Model  NB  for 20 news   tf-idf, remove stopping word best params {'NB__alpha': 0.2, 'NB__fit_prior': False}\n",
      "Model  NB  for IMDB  tf-idf, remove stopping word  score = 0.8380\n",
      "Model  NB  for IMDB  tf-idf, remove stopping word  best params {'NB__alpha': 1.8, 'NB__fit_prior': True}\n",
      "----------\n",
      "Model  NB  is not suitable for non-negative value in preprocessing  SVD-2\n",
      "----------\n",
      "Model  NB  is not suitable for non-negative value in preprocessing  SVD-3\n",
      "----------\n",
      "Model  NB  is not suitable for non-negative value in preprocessing  SVD-4\n",
      "----------\n",
      "Model  NB  is not suitable for non-negative value in preprocessing  SVD-5\n",
      "----------\n",
      "Model  NB  is not suitable for non-negative value in preprocessing  SVD-6\n",
      "----------\n",
      "####################\n",
      "Model  LR  for 20 news  tf-idf score = 0.7776\n",
      "Model  LR  for 20 news   tf-idf best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  tf-idf  score = 0.8832\n",
      "Model  LR  for IMDB  tf-idf  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "Model  LR  for 20 news  tf-idf, remove stopping word score = 0.7894\n",
      "Model  LR  for 20 news   tf-idf, remove stopping word best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  tf-idf, remove stopping word  score = 0.8830\n",
      "Model  LR  for IMDB  tf-idf, remove stopping word  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "Model  LR  for 20 news  SVD-2 score = 0.1693\n",
      "Model  LR  for 20 news   SVD-2 best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  SVD-2  score = 0.8830\n",
      "Model  LR  for IMDB  SVD-2  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "Model  LR  for 20 news  SVD-3 score = 0.2524\n",
      "Model  LR  for 20 news   SVD-3 best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  SVD-3  score = 0.8830\n",
      "Model  LR  for IMDB  SVD-3  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "Model  LR  for 20 news  SVD-4 score = 0.3135\n",
      "Model  LR  for 20 news   SVD-4 best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  SVD-4  score = 0.8830\n",
      "Model  LR  for IMDB  SVD-4  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "Model  LR  for 20 news  SVD-5 score = 0.3484\n",
      "Model  LR  for 20 news   SVD-5 best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  SVD-5  score = 0.8830\n",
      "Model  LR  for IMDB  SVD-5  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "Model  LR  for 20 news  SVD-6 score = 0.3743\n",
      "Model  LR  for 20 news   SVD-6 best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "Model  LR  for IMDB  SVD-6  score = 0.8830\n",
      "Model  LR  for IMDB  SVD-6  best params {'LR__penalty': 'l2', 'LR__warm_start': True}\n",
      "----------\n",
      "####################\n",
      "Model  DT  for 20 news  tf-idf score = 0.4806\n",
      "Model  DT  for 20 news   tf-idf best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "Model  DT  for IMDB  tf-idf  score = 0.7025\n",
      "Model  DT  for IMDB  tf-idf  best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "----------\n",
      "Model  DT  for 20 news  tf-idf, remove stopping word score = 0.5050\n",
      "Model  DT  for 20 news   tf-idf, remove stopping word best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "Model  DT  for IMDB  tf-idf, remove stopping word  score = 0.7106\n",
      "Model  DT  for IMDB  tf-idf, remove stopping word  best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "----------\n",
      "Model  DT  for 20 news  SVD-2 score = 0.1394\n",
      "Model  DT  for 20 news   SVD-2 best params {'DT__criterion': 'gini', 'DT__max_features': 'sqrt'}\n",
      "Model  DT  for IMDB  SVD-2  score = 0.7182\n",
      "Model  DT  for IMDB  SVD-2  best params {'DT__criterion': 'entropy', 'DT__max_features': None}\n",
      "----------\n",
      "Model  DT  for 20 news  SVD-3 score = 0.1984\n",
      "Model  DT  for 20 news   SVD-3 best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "Model  DT  for IMDB  SVD-3  score = 0.7096\n",
      "Model  DT  for IMDB  SVD-3  best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "----------\n",
      "Model  DT  for 20 news  SVD-4 score = 0.2597\n",
      "Model  DT  for 20 news   SVD-4 best params {'DT__criterion': 'gini', 'DT__max_features': 'sqrt'}\n",
      "Model  DT  for IMDB  SVD-4  score = 0.7212\n",
      "Model  DT  for IMDB  SVD-4  best params {'DT__criterion': 'entropy', 'DT__max_features': None}\n",
      "----------\n",
      "Model  DT  for 20 news  SVD-5 score = 0.2994\n",
      "Model  DT  for 20 news   SVD-5 best params {'DT__criterion': 'gini', 'DT__max_features': None}\n",
      "Model  DT  for IMDB  SVD-5  score = 0.7201\n",
      "Model  DT  for IMDB  SVD-5  best params {'DT__criterion': 'entropy', 'DT__max_features': None}\n",
      "----------\n",
      "Model  DT  for 20 news  SVD-6 score = 0.3241\n",
      "Model  DT  for 20 news   SVD-6 best params {'DT__criterion': 'entropy', 'DT__max_features': None}\n",
      "Model  DT  for IMDB  SVD-6  score = 0.7214\n",
      "Model  DT  for IMDB  SVD-6  best params {'DT__criterion': 'entropy', 'DT__max_features': None}\n",
      "----------\n",
      "####################\n",
      "Model  SVC  for 20 news  tf-idf score = 0.8036\n",
      "Model  SVC  for 20 news   tf-idf best params {'SVC__loss': 'squared_hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  tf-idf  score = 0.8826\n",
      "Model  SVC  for IMDB  tf-idf  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "Model  SVC  for 20 news  tf-idf, remove stopping word score = 0.8028\n",
      "Model  SVC  for 20 news   tf-idf, remove stopping word best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  tf-idf, remove stopping word  score = 0.8780\n",
      "Model  SVC  for IMDB  tf-idf, remove stopping word  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "Model  SVC  for 20 news  SVD-2 score = 0.1543\n",
      "Model  SVC  for 20 news   SVD-2 best params {'SVC__loss': 'squared_hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  SVD-2  score = 0.8780\n",
      "Model  SVC  for IMDB  SVD-2  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "Model  SVC  for 20 news  SVD-3 score = 0.2513\n",
      "Model  SVC  for 20 news   SVD-3 best params {'SVC__loss': 'squared_hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  SVD-3  score = 0.8780\n",
      "Model  SVC  for IMDB  SVD-3  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "Model  SVC  for 20 news  SVD-4 score = 0.2941\n",
      "Model  SVC  for 20 news   SVD-4 best params {'SVC__loss': 'squared_hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  SVD-4  score = 0.8780\n",
      "Model  SVC  for IMDB  SVD-4  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "Model  SVC  for 20 news  SVD-5 score = 0.3279\n",
      "Model  SVC  for 20 news   SVD-5 best params {'SVC__loss': 'squared_hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  SVD-5  score = 0.8780\n",
      "Model  SVC  for IMDB  SVD-5  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "Model  SVC  for 20 news  SVD-6 score = 0.3540\n",
      "Model  SVC  for 20 news   SVD-6 best params {'SVC__loss': 'squared_hinge', 'SVC__penalty': 'l2'}\n",
      "Model  SVC  for IMDB  SVD-6  score = 0.8780\n",
      "Model  SVC  for IMDB  SVD-6  best params {'SVC__loss': 'hinge', 'SVC__penalty': 'l2'}\n",
      "----------\n",
      "####################\n",
      "Model  ADB  for 20 news  tf-idf score = 0.5046\n",
      "Model  ADB  for 20 news   tf-idf best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 100}\n",
      "Model  ADB  for IMDB  tf-idf  score = 0.8357\n",
      "Model  ADB  for IMDB  tf-idf  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "Model  ADB  for 20 news  tf-idf, remove stopping word score = 0.5127\n",
      "Model  ADB  for 20 news   tf-idf, remove stopping word best params {'ADB__learning_rate': 0.4, 'ADB__n_estimators': 120}\n",
      "Model  ADB  for IMDB  tf-idf, remove stopping word  score = 0.8359\n",
      "Model  ADB  for IMDB  tf-idf, remove stopping word  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "Model  ADB  for 20 news  SVD-2 score = 0.1460\n",
      "Model  ADB  for 20 news   SVD-2 best params {'ADB__learning_rate': 0.4, 'ADB__n_estimators': 30}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  ADB  for IMDB  SVD-2  score = 0.8359\n",
      "Model  ADB  for IMDB  SVD-2  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "Model  ADB  for 20 news  SVD-3 score = 0.2135\n",
      "Model  ADB  for 20 news   SVD-3 best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 30}\n",
      "Model  ADB  for IMDB  SVD-3  score = 0.8359\n",
      "Model  ADB  for IMDB  SVD-3  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "Model  ADB  for 20 news  SVD-4 score = 0.2820\n",
      "Model  ADB  for 20 news   SVD-4 best params {'ADB__learning_rate': 0.4, 'ADB__n_estimators': 50}\n",
      "Model  ADB  for IMDB  SVD-4  score = 0.8359\n",
      "Model  ADB  for IMDB  SVD-4  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "Model  ADB  for 20 news  SVD-5 score = 0.3190\n",
      "Model  ADB  for 20 news   SVD-5 best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 30}\n",
      "Model  ADB  for IMDB  SVD-5  score = 0.8359\n",
      "Model  ADB  for IMDB  SVD-5  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "Model  ADB  for 20 news  SVD-6 score = 0.3375\n",
      "Model  ADB  for 20 news   SVD-6 best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 50}\n",
      "Model  ADB  for IMDB  SVD-6  score = 0.8359\n",
      "Model  ADB  for IMDB  SVD-6  best params {'ADB__learning_rate': 0.6000000000000001, 'ADB__n_estimators': 120}\n",
      "----------\n",
      "####################\n",
      "Model  RDF  for 20 news  tf-idf score = 0.6768\n",
      "Model  RDF  for 20 news   tf-idf best params {'RDF__criterion': 'gini', 'RDF__max_features': 'log2'}\n",
      "Model  RDF  for IMDB  tf-idf  score = 0.8387\n",
      "Model  RDF  for IMDB  tf-idf  best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "Model  RDF  for 20 news  tf-idf, remove stopping word score = 0.7197\n",
      "Model  RDF  for 20 news   tf-idf, remove stopping word best params {'RDF__criterion': 'gini', 'RDF__max_features': 'log2'}\n",
      "Model  RDF  for IMDB  tf-idf, remove stopping word  score = 0.8525\n",
      "Model  RDF  for IMDB  tf-idf, remove stopping word  best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "Model  RDF  for 20 news  SVD-2 score = 0.1567\n",
      "Model  RDF  for 20 news   SVD-2 best params {'RDF__criterion': 'gini', 'RDF__max_features': 'log2'}\n",
      "Model  RDF  for IMDB  SVD-2  score = 0.8520\n",
      "Model  RDF  for IMDB  SVD-2  best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "Model  RDF  for 20 news  SVD-3 score = 0.2609\n",
      "Model  RDF  for 20 news   SVD-3 best params {'RDF__criterion': 'gini', 'RDF__max_features': 'sqrt'}\n",
      "Model  RDF  for IMDB  SVD-3  score = 0.8530\n",
      "Model  RDF  for IMDB  SVD-3  best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "Model  RDF  for 20 news  SVD-4 score = 0.3380\n",
      "Model  RDF  for 20 news   SVD-4 best params {'RDF__criterion': 'gini', 'RDF__max_features': 'log2'}\n",
      "Model  RDF  for IMDB  SVD-4  score = 0.8534\n",
      "Model  RDF  for IMDB  SVD-4  best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "Model  RDF  for 20 news  SVD-5 score = 0.3813\n",
      "Model  RDF  for 20 news   SVD-5 best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "Model  RDF  for IMDB  SVD-5  score = 0.8537\n",
      "Model  RDF  for IMDB  SVD-5  best params {'RDF__criterion': 'entropy', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "Model  RDF  for 20 news  SVD-6 score = 0.4286\n",
      "Model  RDF  for 20 news   SVD-6 best params {'RDF__criterion': 'gini', 'RDF__max_features': 'log2'}\n",
      "Model  RDF  for IMDB  SVD-6  score = 0.8506\n",
      "Model  RDF  for IMDB  SVD-6  best params {'RDF__criterion': 'gini', 'RDF__max_features': 'sqrt'}\n",
      "----------\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# No preprocessing scalar added\n",
    "grid_dict_20 = {}\n",
    "grid_dict_imdb = {}\n",
    "scores = np.zeros((2,len(models_list),len(dataset_list)))\n",
    "\n",
    "k = 5 # Magic number\n",
    "n_jobs =5\n",
    "\n",
    "for idx,model_item in tqdm_notebook(enumerate(models_list),total=len(models_list)):\n",
    "    pipline = Pipeline([model_item])\n",
    "    print('#'*20)\n",
    "    # For 20 news\n",
    "    grid_20 = GridSearchCV(pipline,param_grid=params_list[idx],cv=k,\n",
    "                        error_score=0.0,n_jobs=n_jobs)\n",
    "    # For imdb\n",
    "    grid_imdb = GridSearchCV(pipline,param_grid=params_list[idx],cv=k,\n",
    "                        error_score=0.0,n_jobs=n_jobs)\n",
    "    \n",
    "    for dataset_idx in range(len(twenty_dataset_dict)):\n",
    "        try:\n",
    "            grid_20.fit(twenty_dataset_dict[dataset_idx][0],twenty_dataset_dict[dataset_idx][1])\n",
    "            scores[0,idx,dataset_idx] = grid_20.score(twenty_dataset_dict[dataset_idx][2], twenty_dataset_dict[dataset_idx][3])\n",
    "            print('Model ',model_item[0],' for 20 news ' , dataset_list[dataset_idx] ,'score = %3.4f'%(scores[0,idx,dataset_idx]))\n",
    "            print('Model ',model_item[0],' for 20 news  ' , dataset_list[dataset_idx] ,'best params', grid_20.best_params_)\n",
    "            grid_dict_20[model_item[0]] = grid_20\n",
    "\n",
    "\n",
    "\n",
    "            grid_imdb.fit(IMDB_dataset_dict[dataset_idx][0],IMDB_dataset_dict[dataset_idx][1])\n",
    "            scores[1,idx,dataset_idx] = grid_imdb.score(IMDB_dataset_dict[dataset_idx][2], IMDB_dataset_dict[dataset_idx][3])\n",
    "            print('Model ',model_item[0],' for IMDB ' , dataset_list[dataset_idx] ,' score = %3.4f'%(scores[1,idx,dataset_idx]))\n",
    "            print('Model ',model_item[0],' for IMDB ' , dataset_list[dataset_idx] ,' best params', grid_imdb.best_params_)\n",
    "            grid_dict_imdb[model_item[0]] = grid_imdb\n",
    "        except ValueError as e:\n",
    "            print('Model ',model_item[0], ' is not suitable for non-negative value in preprocessing ',dataset_list[dataset_idx])\n",
    "        print('-'*10)\n",
    "    \n",
    "joblib.dump(grid_dict_20,'grid_dict_20.asv')\n",
    "joblib.dump(grid_dict_imdb,'grid_dict_imdb.asv')\n",
    "joblib.dump(scores,'scores.asv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
